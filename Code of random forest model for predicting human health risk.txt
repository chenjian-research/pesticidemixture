import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from itertools import cycle
plt.rcParams['figure.figsize']=(25, 10)
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize, LabelEncoder
from sklearn.multiclass import OneVsRestClassifier 
from sklearn.impute import SimpleImputer
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score
from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix
from sklearn.datasets import make_classification
from sklearn.metrics import make_scorer
from sklearn.model_selection import GridSearchCV
from scipy import interp

# read data
dataset=pd.read_csv(r'D:\1work\1 PhD\RFpesticide\humanhealth1.csv')
cols=['Risk_level','risklevel']
for col in cols:
    dataset[col] = dataset[col].astype('category')

# Splitting the dataset into the training set and test set
X=dataset.drop(['Risk_level','risklevel'],axis=1)
Type=dataset.Risk_level
X_train,X_test,y_train,y_test=train_test_split(X,Type,test_size=0.2,random_state=80,stratify=Type)

# handling missing data in the trainset
X_train.fillna(0,inplace=True)
X_test.fillna(0,inplace=True)
skf = StratifiedKFold(n_splits=10)

# choose the best n_estimators
scorel = []
for i in range(1,500,1):
    rfc1 = RandomForestClassifier(n_estimators=i, n_jobs=-1, random_state=50)
    score = cross_val_score(rfc1, X_train, y_train, cv=skf).mean()
    scorel.append(score)
print(max(scorel),(scorel.index(max(scorel))))
plt.figure(figsize=[20,5])
plt.plot(range(1,500,1),scorel)
plt.show()#best n_estimators=179

#chose the best max_depth
param_grid = {'max_depth':np.arange(1,30,1)} 
rfc1 = RandomForestClassifier(n_estimators=179,random_state=50) 
GS = GridSearchCV(rfc1,param_grid,cv=skf)
GS.fit(X_train,y_train)
GS.best_params_#best max_depth=16
GS.best_score_
#chose the best min_samples_leaf
param_grid={'min_samples_leaf':np.arange(1, 11, 1)}
rfc = RandomForestClassifier(n_estimators=179,random_state=50,max_depth=16)
GS = GridSearchCV(rfc,param_grid,cv=skf)
GS.fit(X_train,y_train)
GS.best_params_#best min_samples_leaf=1
GS.best_score_
#chose the best min_samples_split
param_grid={'min_samples_split':np.arange(2, 2+20, 1)}
rfc = RandomForestClassifier(n_estimators=179,random_state=50,max_depth=16,min_samples_leaf=1)
GS = GridSearchCV(rfc,param_grid,cv=skf)
GS.fit(X_train,y_train)
GS.best_params_#best min_samples_split=2
GS.best_score_
#chose the best max_features
param_grid = {'max_features':np.arange(1,10,1)} 
rfc = RandomForestClassifier(n_estimators=179,random_state=50,max_depth=16,min_samples_leaf=1,min_samples_split=2)
GS = GridSearchCV(rfc,param_grid,cv=skf)
GS.fit(X_train,y_train)
GS.best_params_#best max_features=5
GS.best_score_
#chose the best criterion
param_grid = {'criterion':['gini', 'entropy']}
rfc = RandomForestClassifier(n_estimators=179,random_state=50,max_depth=16,min_samples_leaf=1,min_samples_split=2,max_features=5)
GS = GridSearchCV(rfc,param_grid,cv=skf)
GS.fit(X_train,y_train)
GS.best_params_#best criterion='gini'
GS.best_score_
# feature importance
from matplotlib import pyplot as plt
rfc = RandomForestClassifier(n_estimators=179,random_state=50,max_depth=16,min_samples_leaf=1,min_samples_split=2,max_features=5,criterion= 'gini')
rfc.fit(X_train,y_train)
sorted_idx=rfc.feature_importances_.argsort()
plt.barh(X_train.columns[sorted_idx],rfc.feature_importances_[sorted_idx])

from sklearn.metrics import auc
cols=['Risk_level','risklevel']
for col in cols:
    dataset[col] = dataset[col].astype('category')
X=dataset.drop(['Risk_level','risklevel'],axis=1)
Type=dataset.Risk_level
X_train,X_test,y_train,y_test=train_test_split(X,Type,test_size=0.2,random_state=80,stratify=Type)
X_train.fillna(0,inplace=True)
X_test.fillna(0,inplace=True)
rfc2 = RandomForestClassifier(n_estimators=179,random_state=50,max_depth=16,min_samples_leaf=1,min_samples_split=2,max_features=5,criterion= 'gini')
y_score = rfc2.fit(X_train, y_train).predict_proba(X_test)
fpr, tpr, thresholds = roc_curve(y_test, y_score[:, 1])
auc1 = auc(fpr, tpr)
#calculate the Accuracy, Precision and AUC
rfc_prime= rfc2.fit(X_train,y_train)
y_predict = rfc_prime.predict(X_test)
print("Accuracy",accuracy_score(y_test,y_predict))
print('Precision',precision_score(y_test,y_predict,average='macro'))
print("AUC",auc1)

#plot the ROC
print(auc1)
plt.figure()
lw = 2
plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % auc1) 
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.02])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()